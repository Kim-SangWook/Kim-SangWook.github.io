1. INTRODUCTION AND LITERATURE REVIEW
=====================================

통계적 방법은 종종 데이터가 특정분포를 따른다는 가정을 기반으로
도출된다.

가정된 분포에 상관없이 결론의 타당성은 확률모델이 얼마나 데이터에 잘
피팅되는지에 달려있다.

따라서 타당한 분석을 하려면 기본 데이터 모델이 가정을 충족하는지
검정하는 적합도 테스트를 개발하는것이 중요하다.

일반적으로 gof는 모수적 모델 vs 비모수적 모델 이다.

이러한 테스트를 개발할 때 직면할 과제는 비모수적 모델을 만드는 것이다.

1.1 History of Goodness-of-Fit Testing
--------------------------------------

gof를 단변량 데이터에서의 다변량으로 확장한다.

빈도주의와 베이지안 두 가지에 대해서 보여준다.

### 1.1.1 Frequentist Tests

### 1.1.2 Comparison of Frequentist and Bayesian Hypothesis Testing

적합도 검정에대한 베이지안 접근을 설명하기 전에 빈도주의 vs 베이지안
비교하면서 베이지안을 선호하는 이유에 대해 먼저 설명한다.

빈도주의적 적합도 검정에서 가설은 일반적으로 다음과 같다.
$$
\\begin{array}{l}
H\_{0}: Y\_{1}, \\ldots, Y\_{n} \\sim f(\\cdot \\mid \\theta \\in \\Theta) \\\\
H\_{1}: Y\_{1}, \\ldots, Y\_{n} \\nsim f(\\cdot \\mid \\theta \\in \\Theta)
\\end{array}
$$

p-값이 작을 경우 null을 기각하지만 대안 모델이 모호한 경우 모델에 대한
정보는 거의 없다.

p-값이 클 경우 null을 기각하진 못하지만 null이 True라는 것은 아니다.
일반적인 p=0.05을 이용한 결론은 종종 null에 대해서 더많은 증거가
있을수있다.

큰데이터(n -&gt; 무한대로 간다면)에서 유의수준이 0이 되어야 한다는
예시도 있다.

따라서 적합도검정에서는 빈도주의적 접근이 바람직하지 않다.

이제 베이지안 관점에서 적합도 검정을 고려하자.
$$
\\begin{array}{l}
H\_{0}: Y\_{1}, \\ldots, Y\_{n} \\sim f(\\cdot \\mid \\theta \\in \\Theta) \\\\
H\_{1}: Y\_{1}, \\ldots, Y\_{n} \\nsim f(\\cdot \\mid \\theta \\in \\Theta)
\\end{array}
$$
we compute the Bayes factor in favor of the alternative model
$$
\\mathrm{BF}=\\frac{\\int\\left\[\\prod\_{i=1}^{n} g\\left(Y\_{i} \\mid \\theta\_{1}\\right)\\right\] p\\left(\\theta\_{1}\\right) d \\theta\_{1}}{\\int\\left\[\\prod\_{i=1}^{n} f\\left(Y\_{i} \\mid \\theta\_{0}\\right)\\right\] \\pi\\left(\\theta\_{0}\\right) d \\theta\_{0}},
$$
is the ratio of marginal likelihoods

<figure>
<img src="fig1.jpg" style="width:50.0%" alt="베이즈펙터 값에 따른 대안모델에 대한 증거" /><figcaption aria-hidden="true">베이즈펙터 값에 따른 대안모델에 대한 증거</figcaption>
</figure>

베이즈 팩터의 중요한 속성중 하나인 베이즈팩터 일관성(Bayes factor
consistency)는 정의1에 정의되어있다.

#### Definition 1. (Bayes Factor Consistency): The Bayes factor defined by BF comparing the alternative model ℱ<sub>1</sub> to the null model ℱ<sub>0</sub> in Bayesian hypothesis testing is consistent if, as *n* → ∞ :

-   *B**F* → ∞(log (*B**F*) → ∞) when ℱ<sub>1</sub> is the true model;
    and
-   *B**F* → 0(log (*B**F*) →  − ∞) when ℱ<sub>0</sub> is the true
    model.

이는 표본 크기가 증가함에 따라 제 1,2종 오류가 발생할 확률이 0이되는
경향이 있음을 의미한다.

무론 두 모델이 데이터에 적합하지 않아도 하나의 모델이 선호된다. 하지만
여기서 대안모델은 Kullback-Leibler관점에서 True에 가깝게 정의된다.

철학적 관점에서 빈도주의보다 베이지안이 적합도 검정에 적절하다.

베이즈팩터는 귀무가설,대립가설 모두에 대한 주변가능도가 필요하다.

null marginal likelihood은 유한차원에서 적분, 반면 alternative marginal
likelihood 는 종종 매우 높은 차원에서의 적분이기 때문에 어렵다.

따라서 MCMC알고리즘이 필요하여 컴퓨팅의 성능이 낮은 예전에는 빈도주의가
더 선호되었다.

### 1.1.3 Bayesian Tests

단변량 데이터에서의 초기 베이지안 적합도 검정은 대부분 Dirichlet
processes, Polya tree processes, and Gaussian processes를 활용하는
베이지안비모수 밀도추정을 이용하였다.

Dirichlet process를 이용한 베이지안 비모수 적합도 검정, alternative
model은 다음과 같이 정의된다.
$$
\\begin{aligned}
\\mathbf{y} \\mid \\underline{F}, \\underline{\\theta} & \\sim \\prod\_{i=1}^{s} \\prod\_{j=1}^{n\_{i}} F\_{i}\\left(y\_{i j} \\mid \\theta\_{i}\\right), \\quad \\underline{F}=\\left(F\_{1}, \\ldots, F\_{s}\\right) \\in \\mathcal{F} \\quad \\underline{\\theta}=\\left(\\theta\_{1}, \\ldots, \\theta\_{s}\\right) \\in \\Theta \\\\
\\underline{F} \\mid \\underline{\\theta} & \\sim \\prod\_{i=1}^{s} \\mathcal{D}\_{i}, \\quad \\mathcal{D}\_{i} \\sim \\text { Dirichlet process with measure } \\alpha\_{i}\\left(\\theta\_{i}, y\\right) \\\\
\\underline{\\theta} & \\sim \\mathcal{Q}
\\end{aligned}
$$

𝒬 is the prior distribution function of *θ*. 이 두 모델을 사용하면
null을 선호하는 베이즈팩터를 쉽계 계산할 수 있지만 연속적인 null 모델을
검정할 때 디리클레 프로세스를 사용하는 것은 부적절하다.

따라서 다음 접근은 Gaussian process prior in the alternative model. they
embed the parametric null model in an infinite-dimensional exponential
family to form the alternative model ( 무슨 뜻이지..)

The null model is defined by ℱ = {*F*( ⋅  ∣ *θ*) : *θ* ∈ *Ω*} and a
random variable from this model is expressed as
*Y* = *F*<sup> − 1</sup>(*U* ∣ *θ*) where *U* ∼ 𝒰(0, 1) and *θ* ∈ *Ω*,
using the inverse probability integral transform.

The alternative model is an extended model defined by the
infinite-dimensional exponential family of distributions on \[0, 1\],
$\\mathcal{G}=\\{G(\\cdot \\mid \\psi): \\psi \\in \\S\\} .$ If a random
variable *Y* was from this extended model, then *Y* could be expressed
as *Y* = *F*<sup> − 1</sup>(*U* ∣ *θ*) where
*U* ∼ *G*( ⋅  ∣ *ψ*), *θ* ∈ *Ω* and *ψ* ∈ *S*.

When *ψ* = *ψ*<sub>0</sub>, *G*(⋅∣*ψ*<sub>0</sub>) = 𝒰(0, 1) and hence
𝒢 = ℱ.

The probability densities associated with 𝒢 can be written as

$$
g(u \\mid \\psi)=\\exp \\left(\\sum\_{j=1}^{\\infty} \\psi\_{j} \\phi\_{j}(u)-c(\\psi)\\right)
$$

where *ψ* = (*ψ*<sub>1</sub>,*ψ*<sub>2</sub>,…) are the polynomial
coefficients for the rescaled Legendre polyno- mials
*ϕ* = (*ϕ*<sub>1</sub>,*ϕ*<sub>2</sub>,…) and *c*(*ψ*) is the
normalizing constant.

The unknown parameters, *θ* and *ψ* are taken to be independent such
that the prior distribution is given by *p*(*θ*, *ψ*)= *p*(*θ*)*p*(*ψ*).

Take *p*(*θ*) to be any standard reference prior for *θ* and
$p(\\psi)=\\prod\_{j=1}^{\\infty} p\\left(\\psi\_{j} \\mid \\tau\\right) p(\\tau)$
such that each *ψ*<sub>*j*</sub> ∼ *N*(0,*τ*<sup>2</sup>) and *τ*
follows a truncated standard normal distribution on \[0, ∞).

Under this construction,
$\\sum\_{j=1}^{\\infty} \\psi\_{j} \\phi\_{j}(u)$ is a Gaussian process.

MH in gibbs샘플링을 이용하여 베이즈펙터 계산하다. 이 방식은 단변량
데이터에 대해서 연속적인 null모델 적용가능하다.

또 다른 방식은 폴랴트리 프로세스의 혼합을 기반으로 하는 적합도 검정이다.
폴랴트리는 비모수적으로 연속적인 밀도함수를 모델링하고 무정보사전분포를
줄 수 있다.

디리클레프로세스보다 우수하지만 차원이 증가함에 따라 확장되지 않으므로
단량 데이터로 제한된다.

또 다른 방법 by Tokdar and Martin (2013).

test for normality in any dimension using a non- subjective Dirichlet
process mixture of normals as the alternative model.

정규성 테스트에만 적용되는 제한이 있다.

여러가지 적합도 테스트 방법이 있지만 각 베이지안 접근법에는 각각의
단점이 있다. 단변량 데이터 제안, 연속null모델 제한, normal null 모델
제한 또 주변우도계산의 복잡함 등등 여러 단점이 존재한다.

여기서 제안하는 메인 방법은 절대적 연속 null 모델에 대한 다변량 적합도
검정을 하기위한 간단하고 직관적인 방식이다.

1.2 Research Layout
-------------------

챕터 2에서는 examining the univariate *C**V**B**F*<sub>*K*</sub>
method하고 다변량 데이터를 고려하기전에 기초를 다진다.

챕터 3에서는 다변량 커널 밀도추정치를 간략하게 소개하고, bandwidth
matrix가 *C**V**B**F*<sub>*k*</sub>에 잠재적으로 미치는 영향을 소개한다.

챕터 4에서는 2장과 3장을 결합하여 다변량으로확장한다. (메인 파트)

챕터 5에서는 모수적 cvbf방법 설명.

챕터 6은 1-5장 내용을 합쳐 향후 연구에 대한 설명.

2. UNIVARIATE *C**V**B**F*<sub>*K*</sub> METHOD
===============================================

2.1 General Description
-----------------------

called the kernel cross-validated Bayes factor method because we need to
use data splitting in order to compute a kernel estimate.

수많은 무작위 분할에 대한 각강의 베이즈팩터의 기하학적 평균을 결과값으로
한다.

2.2 Formal Methodology
----------------------

알려지지않은 모수밀도함수 g의 샘플:
**X** = (*X*<sub>1</sub>,*X*<sub>2</sub>,…,*X*<sub>*n*</sub>)

Suppose we want to test that *g* = *f*( ⋅  ∣ *θ*), 여기서 f 는 모수벡터
세타로 인덱싱된 특정 밀도 함수이다

여기서 가설은 다음과 같다.
$$
\\begin{array}{l}
H\_{0}: \\mathbf{X}^{V} \\sim M\_{0}=\\{f(\\cdot \\mid \\theta): \\theta \\in \\Theta\\} \\\\
H\_{1}: \\mathbf{X}^{V} \\sim M\_{1}=\\left\\{\\hat{f}\\left(\\cdot \\mid \\mathbf{X}^{T}, h\\right): h&gt;0\\right\\} .
\\end{array}
$$
In the alternative model,
$$
\\hat{f}\\left(x \\mid \\mathbf{X}^{T}, h\\right)=\\frac{1}{m h} \\sum\_{i=1}^{m} K\_{1}\\left(\\frac{x-X\_{i}}{h}\\right)
$$
is the typical univariate kernel density estimator, *K*<sub>1</sub> 는
symmetric, unimodal, finite variance density function으로
취한다.(recommend using the Gaussian kernel function)

데이터 분할

훈련 데이터:
**X**<sup>*T*</sup> = (*X*<sub>1</sub>,*X*<sub>2</sub>,…,*X*<sub>*m*</sub>).

검증 데이터:
**X**<sup>*V*</sup> = (*X*<sub>*m* + 1</sub>,*X*<sub>*m* + 2</sub>,…,*X*<sub>*n*</sub>).

훈련데이터 사이즈의 적절한 설정은 나중에 설명한다.

대립가설 모델을 선호하는 The Bayes factor for a single random split은
다음과 같다.( 여기서 m은 train dataset size)
$$
\\mathrm{BF}\_{m}=\\frac{\\int\_{0}^{\\infty} \\prod\_{j=m+1}^{n} \\hat{f}\\left(X\_{j} \\mid \\mathbf{X}^{T}, h\\right) p(h) d h}{\\int\_{\\Theta} \\prod\_{j=m+1}^{n} f\\left(X\_{j} \\mid \\theta\\right) \\pi(\\theta) d \\theta}
$$
무작위 분할에 대한 의존성을 완화하기 위해서 분할은 k(1~N)번 반복한다.

The resulting *C**V**B**F*<sub>*m*, *N*</sub> value is the geometric
mean,
$$
\\mathrm{CVBF}\_{m, N}=\\left(\\prod\_{k=1}^{N} \\mathrm{BF}\_{m, k}\\right)^{1 / N}
$$

BF를 계산하기 위해 사전분포가 요구된다. *π*(*θ*) and *p*(*h*).

Hart and Choi (2016) suggest taking a unit-information, reference (UIR)
prior for *π*(*θ*).

이 UIR prior를 사용하면 단변량 정규성을 검정할 때 location과 scale에
불면하는 베이즈펙터가 생성된다.

적절한 *p*(*h*)를 찾는것은 조금 더 복잡하다. 일반적으로 커널밀도추저에서
bandwidth는 scale 모수처럼 작용하므로 자연스럽게 먼저 scale-invariant,
improper prior를 고려한다. *p*(*h*) ∝ *h*<sup> − 1</sup>

부적절한 사전분포를 고려하면 BF가 어떤 상수에 비례하게 되기 때문에
intrinsic Bayes factor (IBF) idea proposed by Berger and Perrichi
(1996)의 아이디어를 사용하여 적절한 prior를 찾을 수 있다.

take the minimal sample size so that
$L\\left(X\_{1} \\mid X\_{2}, h\\right) p(h) \\propto h^{-2} K\_{1}\\left(\\frac{X\_{1}-X\_{2}}{h}\\right)$
produces a proper posterior distribution.

For the Gaussian kernel function the proper posterior distribution has a
closed form given by
$$
p(h \\mid \\beta)=\\frac{2 \\beta}{\\sqrt{\\pi} h^{2}} \\exp \\left(-\\frac{\\beta^{2}}{h^{2}}\\right),
$$

where *β*<sup>2</sup> is a robust estimate of
.5*E*\[(*X*<sub>1</sub>−*X*<sub>2</sub>)<sup>2</sup>\] = *σ*<sup>2</sup>
calculated from the validation data

사전 분포와 무관하게 귀무,대립가설 모두에서 BF는 consistent at an
exponential rate

marginal likelihood under the alternative model must be computed
numerically. We prefer to use the Laplace approximation

*C**V**B**F*<sub>*K*</sub>를 구현하려면 훈련사이즈 m과 무작위 분할수 N만
결정하면 됩니다.

authors typically set N = 100.

훈련 세트가 관측치를 충분히 근하기위해 커널추정치에 관측치m이 충분히
필요하므로 0.05n &lt; m &lt; 0.5n

검증데이터보다 커지면 안된다.

이 과정은 null모델 에서 반복적으로 샘플링 하여 이 값이 0을 초과하는
빈도를 가지고 결정하기 때문에 빈도주의적 느낌이 있다.

2.3 Real Data Example: Kevlar Strand Data
-----------------------------------------

It is hypothesized that the lifetimes
(*X*<sub>1</sub>,*X*<sub>2</sub>,…,*X*<sub>100</sub>) constitute a
random sample from a log-normal distribution

if the transformed data *Y*<sub>*i*</sub> = log (*X*<sub>*i*</sub>)
follow a normal distribution.

Figure 2.1 contains a histogram of the log(lifetimes) with a kernel
density estimate (Gaus-sian kernel, *h* = .318 ) and a normal curve
(*μ̂* = 4.84, *σ̂* = 1.24) overlaid.

<figure>
<img src="fig2.jpg" style="width:50.0%" alt="log(time to failure)분포. 커널밀도추정치(실선), 추정된 정규 커브(점선)" /><figcaption aria-hidden="true">log(time to failure)분포. 커널밀도추정치(실선), 추정된 정규 커브(점선)</figcaption>
</figure>

히스토그램과 커널추정치는 정규곡선과 비교하여 left skewed 되어있고
피크점도 높다 따라서 정규성이 부적절하다.

Under the normal null model, we assume the data come from a
*N*(*μ*, *σ*) distribution. Hart and Choi (2016) provide a
normal-inverse gamma UIR prior distribution of the form,
$$
\\pi(\\mu, \\sigma \\mid \\bar{Y}, \\gamma)=\\left(2 \\pi \\sigma^{2}\\right)^{-1 / 2} \\exp \\left\[-\\frac{1}{2 \\sigma^{2}}(\\mu-\\bar{Y})^{2}\\right\] \\frac{2 \\gamma}{\\sqrt{\\pi} \\sigma^{2}} \\exp \\left\[-\\frac{\\gamma^{2}}{\\sigma^{2}}\\right\]
$$
where $\\gamma=\\hat{\\sigma} / \\sqrt{2}$ for
$\\hat{\\sigma}^{2}=\\frac{1}{n-m} \\sum\_{j=m+1}^{n}\\left(Y\_{j}-\\bar{Y}\\right)^{2}$
and $\\bar{Y}=\\frac{1}{n-m} \\sum\_{j=m+1}^{n} Y\_{j} .$ Using the
prior in equation ( 2.4 ) and normal likelihood for validation data
**Y**<sup>*V*</sup>, the marginal likelihood for the null model is,
$$
m\\left(\\mathbf{Y}^{V} \\mid M\_{0}\\right)=\\Gamma\\left(\\frac{n-m+1}{2}\\right)(n-m+1)^{-(n-m+2) / 2} \\pi^{-(n-m+1) / 2} \\hat{\\sigma}^{-(n-m)}
$$

대립가설 모델은 가우시안 커널 함수를 사용한
$\\hat{f}\\left(x \\mid \\mathbf{X}^{T}, h\\right)=\\frac{1}{m h} \\sum\_{i=1}^{m} K\_{1}\\left(\\frac{x-X\_{i}}{h}\\right)$,을
이용하여 커널밀도 추정을 하고 사전분포로는
$p(h \\mid \\beta)=\\frac{2 \\beta}{\\sqrt{\\pi} h^{2}} \\exp \\left(-\\frac{\\beta^{2}}{h^{2}}\\right)$을
이용한다.

따라서 마지널 가능도는 다음과 같다.
$$
\\begin{aligned}
m\\left(\\mathbf{Y}^{V} \\mid M\_{1}\\right)=\\int\_{0}^{\\infty} \\prod\_{j=m+1}^{n}\\left\[(2 \\pi)^{-1 / 2}(m h)^{-1} \\sum\_{i=1}^{m} \\exp \\left(-\\frac{\\left(Y\_{j}-Y\_{i}\\right)^{2}}{2 h^{2}}\\right)\\right\] \\\\
& \\times\\left\[\\frac{2 \\beta}{\\sqrt{\\pi} h^{2}} \\exp \\left(-\\frac{\\beta^{2}}{h^{2}}\\right)\\right\] d h
\\end{aligned}
$$
calibration scheme을 사용하면 CVWE <sub>*m*, *N*</sub>가 계산되고 in
*m* = {5, 6, …, 49, 50} using *N* = 1, 000 random splits.

곡선을 그리면(fig2.2) m=30에서 7.241에서 cVWE가 maximum이 된다. 따라서
m=30으로 설정하고, 다음으로 추정된 null normal모델에서 500개의 샘플들을
추출하여 *C**V**W**E*<sub>30, 100</sub> 500번 계산하고 히스토그램을
그린다.(fig2.2)

<figure>
<img src="fig3.jpg" style="width:50.0%" alt="Left: CVWE for N=1000, m = 5~50, Right: \mathrm{CVWE}_{30,100} from 추정된 null모델에서 추출한 500개의 랜덤샘플들" /><figcaption aria-hidden="true">Left: CVWE for N=1000, m = 5~50, Right: <span class="math inline"><em>C</em><em>V</em><em>W</em><em>E</em><sub>30, 100</sub></span> from 추정된 null모델에서 추출한 500개의 랜덤샘플들</figcaption>
</figure>

All 500 CVWE30,100 values are less than 0 indicating that when m = 30

만약 관측된 데이터가 실제 정규분포라면 CVWE는 음수가 된다.

관측된 CVWE <sub>30, 100</sub> value from the Kevlar data of
7.241 &gt; 5 indicates that there is very strong evidence against the
normal model, which implies log-normality of the original times to
failure is not appropriate.

2.4 Conclusions
---------------

Based on the methodology in Section 2.2, we can see how the CVBFK method
should naturally extend to multivariate data.

3. MULTIVARIATE KERNEL DENSITY ESTIMATIOn
=========================================

다변량 데이터에 대한 커널CVBF를 수행하려면 다변량 커널밀도 추정에 대해서
이해할 필요가 있다.

3.1 Definition
--------------

To estimate a *d* -dimensional multivariate density function
*f*<sub>*d*</sub> for observed data **Y**=
(*Y*<sub>1</sub>,*Y*<sub>2</sub>,…,*Y*<sub>*n*</sub>) where each
*Y*<sub>*i*</sub> ∈ ℝ<sup>*d*</sup>, we can use the multivariate kernel
density estimate which has the following general form (Wand and Jones,
1995 ),
$$
\\hat{f}\_{d}(\\mathbf{y} \\mid \\mathbf{Y}, \\mathbf{H})=n^{-1}|\\mathbf{H}|^{-1 / 2} \\sum\_{i=1}^{n} K\_{d}\\left(\\mathbf{H}^{-1 / 2}\\left(\\mathbf{y}-\\mathbf{Y}\_{i}\\right)\\right) .
$$

scalar smoothing parameter였던 h가 bandwidth matrix, H로 바뀌었다.
symmetric, positive definite matrices.(h&gt;0이었던 것과 유사한 제한)

*K*<sub>*d*</sub>는 d-변량 가우시안 커널함수를 사용한다.(다른것도
가능하지만 이것을 추천)
$$
K\_{d}(\\mathbf{t})=(2 \\pi)^{-d / 2} \\exp \\left(-\\mathbf{t}^{T} \\mathbf{t} / 2\\right)=\\prod\_{l=1}^{d} K\_{1}\\left(t\_{l}\\right)
$$

d-variate Gaussian kernel은 단변량 가우시안 커널의 곱으로 작성될 수 있고
이것은 다변량 가우시안 커널 CVBF에 단변량 가우시안커널 CVBF의 결과를
적용할 수 있음을 뜻한다.

Bandwidth Matrix Classes
------------------------

다변량 커널 밀도 추정에서 bandwidth 행렬은 3가지의 클래스중에서
고려한다. \* Full (Unconstrained): The class of all symmetric, positive
definite bandwidth matrices with $\\frac{d(d+1)}{2}$ parameters, denoted
as ℱ.

-   Diagonal: The class of all diagonal bandwidth matrices with *d*
    parameters, 𝒟=
    {**H**=diag(*h*<sub>1</sub><sup>2</sup>,*h*<sub>2</sub><sup>2</sup>,⋯,*h*<sub>*d*</sub><sup>2</sup>):*h*<sub>*l*</sub>&gt;0,*l*=1,⋯,*d*}

-   Scalar: The class of all diagonal matrices indexed by a single,
    scalar bandwidth,
    𝒮 = {**H**=*h*<sup>2</sup>**I**<sub>*d*</sub>:*h*&gt;0}
